# Mini‑RAG (FAQ + цитаты)

Небольшой, практичный пример Retrieval‑Augmented Generation (RAG) для банковского FAQ.  
Проект показывает **полный цикл**: загрузка локальных документов → индексирование → поиск релевантных пассажей → формирование короткого ответа **с цитатами источников**. Подходит для демонстраций, обучения и быстрых прототипов.

> Важно: демо работает **по локальной базе знаний** (`samples/faq/*.md`). LLM при включении тумблера не «гуглит» и не отвечает «из головы» — он формулирует ответ **только по найденным пассажам**.

---

## Возможности

- **Ингест** `.md`/`.txt` документов и разбиение на чанки‑пассажи.
- **Индекс** TF‑IDF (лёгкий и переносимый; удобно для PoC/демо).
- **Ретривер**: косинусная близость, выдача **top‑k** найденных пассажей.
- **Ответы в двух режимах**:
  1) **Без LLM** — показывается лучший пассаж + список цитат.
  2) **С LLM** — краткий ответ по найденным пассажам через OpenAI или GigaChat.
- **Цитирование**: для каждого пассажa выводится источник (название и псевдо‑URL).
- **Streamlit‑интерфейс** с полем ввода вопроса, настройкой **Top‑k** и тумблером «Использовать LLM».

---

## Что лежит в базе знаний

В `samples/faq/` включены тематические карточки (28 шт.), позволяющие задавать **разные вопросы** и получать разные ответы. Темы, например:

- Премиальный счёт, открытие счёта, виртуальная карта;
- Активация карты, смена ПИН, блокировка/разблокировка, перевыпуск при утере;
- Снятие/внесение наличных, P2P‑переводы, SWIFT‑переводы, увеличение лимитов;
- Курсы валют, мультивалютный счёт, комиссии/тарифы, кэшбэк;
- Накопительный счёт и вклады, потребкредит, ипотека, рефинансирование, овердрафт;
- 3‑D Secure, оспаривание операции (чарджбэк), антифрод;
- Идентификация (KYC), выписки и справки, Apple/Google Pay, безопасность входа.

Вы можете свободно **добавлять свои документы** в эту папку — демо подхватит их при старте.

**Примеры вопросов для демо** (можно вставлять как есть):
- «Я бы хотел открыть премиальный счёт, что мне делать?»
- «Как перевыпустить карту, если потерял?»
- «Как повысить суточный лимит на переводы?»
- «Какие комиссии на SWIFT‑переводы и сколько идут?»
- «Сколько процентов на накопительном счёте и можно ли снимать?»
- «Что делать при спорной операции — как оформить чарджбэк?»
- «Где скачать выписку по счёту за месяц?»

---

## Быстрый старт

```bash
pip install -r requirements.txt
streamlit run demo_streamlit.py
```

Откроется интерфейс: задайте вопрос, выберите **Top‑k**, при желании включите LLM, нажмите **«Искать»**.

---

## Конфигурация LLM (необязательно)

Если хотите, чтобы финальный ответ формировала LLM по найденным пассажам, задайте переменные окружения (или Streamlit secrets).

### OpenAI‑совместимый API
```
PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini
```

### GigaChat
```
PROVIDER=gigachat
GIGACHAT_AUTH=<Authorization Key: base64(client_id:client_secret)>
GIGACHAT_SCOPE=GIGACHAT_API_PERS
GIGACHAT_AUTH_URL=https://ngw.devices.sberbank.ru:9443/api/v2/oauth
GIGACHAT_API_URL=https://gigachat.devices.sberbank.ru/api/v1
# для облака часто:
GIGACHAT_VERIFY=false
GIGACHAT_MODEL=GigaChat
```

Если переменные не заданы — оставьте тумблер LLM выключенным: ответ будет формироваться из лучших пассажей.

---

## Как это работает

```
Документы (samples/faq/*.md)
   ↓  split_into_chunks (по умолчанию 400 с overlap 60)
TF‑IDF индекс (TfidfVectorizer, n‑граммы 1–2)
   ↓
Запрос пользователя → вектор запроса
   ↓
Косинусная близость → top‑k пассажей (score, title, url, passage)
   ↓
Ответ:
  (A) Без LLM — лучший пассаж + цитаты
  (B) С LLM   — короткий ответ по контексту + ссылки [1], [2], ...
```

> В промышленной версии индекс обычно заменяют на **эмбеддинги + FAISS/Chroma** и добавляют **reranker** (bge‑reranker / cross‑encoder), кеш, строгие контракты вывода и guardrails.

---

## Структура проекта

```
mini-rag-faq/
├── demo_streamlit.py            # Streamlit-демо (использует пакет из ./src)
├── requirements.txt
├── README.md
├── src/ragmini/
│   ├── __init__.py
│   ├── ingest.py                # ingest, разбиение, TF‑IDF индекс
│   ├── search.py                # косинус и top‑k отбор
│   └── providers.py             # провайдеры OpenAI/GigaChat (чат)
└── samples/faq/*.md             # база знаний для демо
```

---

## Использование как библиотеки

```python
from ragmini import read_docs, build_corpus, build_tfidf_index, search

docs = read_docs("samples/faq")
corpus, meta = build_corpus(docs)
vect, mat = build_tfidf_index(corpus)

hits = search("Как перевыпустить карту?", vect, mat, corpus, meta, k=5)
for i, h in enumerate(hits, 1):
    print(i, h["title"], h["score"])
```

С формированием ответа LLM:
```python
from ragmini import get_chat_provider
provider = get_chat_provider()
context = "\\n\\n".join(f"[{i+1}] {h['passage']} (src: {h['url']})" for i,h in enumerate(hits))
messages = [
  {"role":"system","content":"Ты ассистент банка. Отвечай по делу и ссылайся на [номер]."},
  {"role":"user","content": f"Вопрос: как перевыпустить карту?\\n\\nКонтекст:\\n{context}"}
]
answer = provider.chat(messages, temperature=0.0, max_tokens=400)
print(answer)
```

---

## Советы по качеству (без перехода на FAISS)

- В `TfidfVectorizer` можно включить русскую стоп‑лексику: `stop_words='russian'`.
- Поиграйте размерами чанков: `size=500..700`, `overlap=80..120` — меньше шансов «порвать» смысл.
- Увеличьте `top‑k` при сложных запросах; включайте LLM для более естественных ответов (когда есть контекст).

---

## Ограничения

- TF‑IDF чувствителен к формулировкам; семантический поиск на эмбеддингах будет лучше.
- Нет reranker‑а и кеша индекса — сделано специально просто, для учебных/демо задач.

---

## Лицензия

MIT — свободно для коммерческого использования, форков и модификаций.
